{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c53c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "from coremerge import get_world_gaussian, get_transmats, get_product\n",
    "from snn import define_object_pose, produce_snn_stats\n",
    "from visuals import plot_gaussians, visualize_3d\n",
    "from utils import data2text, generate_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4091274b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This function produces 3 PDFs from SNN stats and one from the product of these\n",
    "The function plots the PDFs (in 3 subplots, one per axis) and returns two arrays: mu and sigma\n",
    "'''\n",
    "def emulate_SNN_with_pose_transformation(nb_pts, cam_poses, ground_truth, e_per, scenario):\n",
    "\n",
    "    ## Get info from: optitrack (camera poses) + snn (object poses + stds)\n",
    "    try:\n",
    "        # Get transformation matrix (from camera to world) for each camera\n",
    "        c2w = get_transmats(cam_poses)\n",
    "\n",
    "        # Define object pose: ground truth and as seen from each camera\n",
    "        perspective = define_object_pose(c2w, ground_truth)\n",
    "\n",
    "        # Get stats from validation dataset\n",
    "        cam_pdf_params = produce_snn_stats(e_per)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Merge observations (This is the core of the 'problem')\n",
    "    try:        \n",
    "        start = time.time()\n",
    "\n",
    "        # Get PDFs from SNN 'observations' (mu|sigma in camera space for each axis|camera)\n",
    "        mu_c, sigma_c = recenter_gaussians(perspective, cam_pdf_params)  \n",
    "\n",
    "        # Convert gaussians from camera space to world space and generate PDFs\n",
    "        mu_w, sigma_w = get_world_gaussian(mu_c, sigma_c, c2w)\n",
    "\n",
    "        stop = time.time()\n",
    "        elapsed = stop - start\n",
    "        print(\"Global x,y,z obtained after: \" + str(1000000*elapsed) + \" us\")     \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Visualize Gaussians\n",
    "    try:\n",
    "        xyz_w, pdf_w = generate_pdfs(nb_pts, ground_truth, mu_w, sigma_w) \n",
    "        text = data2text(ground_truth, cam_poses, mu_c, sigma_c, mu_w, sigma_w)\n",
    "        plot_gaussians(xyz_w, pdf_w, text, scenario)    \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return mu_w, sigma_w\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ce79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9561cda3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cameras at the origin, same <mu|sigma>_<x|y|z> for all cameras\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mu_w' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_148176/3439598699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mscenario\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmu_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memulate_SNN_with_pose_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_148176/1795119654.py\u001b[0m in \u001b[0;36memulate_SNN_with_pose_transformation\u001b[0;34m(nb_pts, cam_poses, ground_truth, e_per, scenario)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmu_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'mu_w' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_pts = 2000\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "cam_poses = np.zeros((3,6)) # 3 cameras, 6 parameters\n",
    "\n",
    "# Cam 1\n",
    "cam_poses[0,0] = 0 # cam1:cx\n",
    "cam_poses[0,1] = 0 # cam1:cy\n",
    "cam_poses[0,2] = 0 # cam1:cz\n",
    "cam_poses[0,3] = (math.pi/180)*(0) # cam1:alpha\n",
    "cam_poses[0,4] = (math.pi/180)*(0) # cam1:beta\n",
    "cam_poses[0,5] = (math.pi/180)*(0) # cam1:gamma\n",
    "\n",
    "# Cam 2\n",
    "cam_poses[1,0] = 0 # cam2:cx\n",
    "cam_poses[1,1] = 0 # cam2:cy\n",
    "cam_poses[1,2] = 0 # cam2:cz\n",
    "cam_poses[1,3] = (math.pi/180)*(0) # cam2:alpha\n",
    "cam_poses[1,4] = (math.pi/180)*(0) # cam2:beta\n",
    "cam_poses[1,5] = (math.pi/180)*(0) # cam2:gamma\n",
    "\n",
    "# Cam 3\n",
    "cam_poses[2,0] = 0 # cam3:cx\n",
    "cam_poses[2,1] = 0 # cam3:cy\n",
    "cam_poses[2,2] = 0 # cam3:cz\n",
    "cam_poses[2,3] = (math.pi/180)*(0)# cam3:alpha\n",
    "cam_poses[2,4] = (math.pi/180)*(0)# cam3:beta\n",
    "cam_poses[2,5] = (math.pi/180)*(0)# cam3:gamma\n",
    "\n",
    "# Object's pose\n",
    "ground_truth = [-0.3, 0.6, 0.5, 1]\n",
    "\n",
    "# Max error per axis (it applies to all cameras)\n",
    "e_per = np.array([0.02, 0.03, 0.18]) # 2%, 3%, 18%\n",
    "\n",
    "print(\"All cameras at the origin, same <mu|sigma>_<x|y|z> for all cameras\")\n",
    "scenario += 1\n",
    "\n",
    "mu_w, sigma_w = emulate_SNN_with_pose_transformation(nb_pts, cam_poses, ground_truth, e_per, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2343c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nb_pts = 2000\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "cam_poses = np.zeros((3,6)) # 3 cameras, 6 parameters\n",
    "\n",
    "# Cam 1\n",
    "cam_poses[0,0] = -0.1 # cam1:cx\n",
    "cam_poses[0,1] =  0.8 # cam1:cy\n",
    "cam_poses[0,2] =  0.9 # cam1:cz\n",
    "cam_poses[0,3] = (math.pi/180)*(0) # cam1:alpha\n",
    "cam_poses[0,4] = (math.pi/180)*(0) # cam1:beta\n",
    "cam_poses[0,5] = (math.pi/180)*(0) # cam1:gamma\n",
    "\n",
    "# Cam 2\n",
    "cam_poses[1,0] = -0.5 # cam2:cx\n",
    "cam_poses[1,1] =  0.8 # cam2:cy\n",
    "cam_poses[1,2] =  0.9 # cam2:cz\n",
    "cam_poses[1,3] = (math.pi/180)*(0) # cam2:alpha\n",
    "cam_poses[1,4] = (math.pi/180)*(0) # cam2:beta\n",
    "cam_poses[1,5] = (math.pi/180)*(0) # cam2:gamma\n",
    "\n",
    "# Cam 3\n",
    "cam_poses[2,0] = -0.5 # cam3:cx\n",
    "cam_poses[2,1] =  0.8 # cam3:cy\n",
    "cam_poses[2,2] =  0.1 # cam3:cz\n",
    "cam_poses[2,3] = (math.pi/180)*(0)# cam3:alpha\n",
    "cam_poses[2,4] = (math.pi/180)*(0)# cam3:beta\n",
    "cam_poses[2,5] = (math.pi/180)*(0)# cam3:gamma\n",
    "\n",
    "# Object's pose\n",
    "ground_truth = [-0.3, 0.6, 0.5, 1]\n",
    "\n",
    "# Max error per axis (it applies to all cameras)\n",
    "e_per = np.array([0.02, 0.03, 0.18]) \n",
    "\n",
    "print(\"All cameras with different (x, y, z) coordinates, same <mu|sigma>_<x|y|z> for all cameras\")\n",
    "scenario += 1\n",
    "\n",
    "mu_w, sigma_w = emulate_SNN_with_pose_transformation(nb_pts, cam_poses, ground_truth, e_per, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b9e14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nb_pts = 2000\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "cam_poses = np.zeros((3,6)) # 3 cameras, 6 parameters\n",
    "\n",
    "# Cam 1\n",
    "cam_poses[0,0] = -0.1 # cam1:cx\n",
    "cam_poses[0,1] =  0.8 # cam1:cy\n",
    "cam_poses[0,2] =  0.9 # cam1:cz\n",
    "cam_poses[0,3] = (math.pi/180)*(0) # cam1:alpha\n",
    "cam_poses[0,4] = (math.pi/180)*(0) # cam1:beta\n",
    "cam_poses[0,5] = (math.pi/180)*(0) # cam1:gamma\n",
    "\n",
    "# Cam 2\n",
    "cam_poses[1,0] = -0.5 # cam2:cx\n",
    "cam_poses[1,1] =  0.8 # cam2:cy\n",
    "cam_poses[1,2] =  0.9 # cam2:cz\n",
    "cam_poses[1,3] = (math.pi/180)*(0) # cam2:alpha\n",
    "cam_poses[1,4] = (math.pi/180)*(0) # cam2:beta\n",
    "cam_poses[1,5] = (math.pi/180)*(0) # cam2:gamma\n",
    "\n",
    "# Cam 3\n",
    "cam_poses[2,0] = -0.5 # cam3:cx\n",
    "cam_poses[2,1] =  0.8 # cam3:cy\n",
    "cam_poses[2,2] =  0.1 # cam3:cz\n",
    "cam_poses[2,3] = (math.pi/180)*(0)# cam3:alpha\n",
    "cam_poses[2,4] = (math.pi/180)*(-90)# cam3:beta\n",
    "cam_poses[2,5] = (math.pi/180)*(0)# cam3:gamma\n",
    "\n",
    "# Object's pose\n",
    "ground_truth = [-0.3, 0.6, 0.5, 1]\n",
    "\n",
    "# Max error per axis (it applies to all cameras)\n",
    "e_per = np.array([0.02, 0.03, 0.18]) \n",
    "\n",
    "print(\"Two cameras aligned, same <mu|sigma>_<x|y|z> for all cameras\")\n",
    "scenario += 1\n",
    "\n",
    "mu_w, sigma_w = emulate_SNN_with_pose_transformation(nb_pts, cam_poses, ground_truth, e_per, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bba48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_pts = 2000\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "cam_poses = np.zeros((3,6)) # 3 cameras, 6 parameters\n",
    "\n",
    "# Cam 1\n",
    "cam_poses[0,0] = -0.1 # cam1:cx\n",
    "cam_poses[0,1] =  0.8 # cam1:cy\n",
    "cam_poses[0,2] =  0.9 # cam1:cz\n",
    "cam_poses[0,3] = (math.pi/180)*(-20) # cam1:alpha\n",
    "cam_poses[0,4] = (math.pi/180)*(45) # cam1:beta\n",
    "cam_poses[0,5] = (math.pi/180)*(0) # cam1:gamma\n",
    "\n",
    "# Cam 2\n",
    "cam_poses[1,0] = -0.5 # cam2:cx\n",
    "cam_poses[1,1] =  0.8 # cam2:cy\n",
    "cam_poses[1,2] =  0.9 # cam2:cz\n",
    "cam_poses[1,3] = (math.pi/180)*(-20) # cam2:alpha\n",
    "cam_poses[1,4] = (math.pi/180)*(-45) # cam2:beta\n",
    "cam_poses[1,5] = (math.pi/180)*(0) # cam2:gamma\n",
    "\n",
    "# Cam 3\n",
    "cam_poses[2,0] = -0.5 # cam3:cx\n",
    "cam_poses[2,1] =  0.8 # cam3:cy\n",
    "cam_poses[2,2] =  0.1 # cam3:cz\n",
    "cam_poses[2,3] = (math.pi/180)*(-20)# cam3:alpha\n",
    "cam_poses[2,4] = (math.pi/180)*(-150)# cam3:beta\n",
    "cam_poses[2,5] = (math.pi/180)*(0)# cam3:gamma\n",
    "\n",
    "# Object's pose\n",
    "ground_truth = [-0.3, 0.6, 0.5, 1]\n",
    "\n",
    "# Max error per axis (it applies to all cameras)\n",
    "e_per = np.array([0.02, 0.03, 0.18]) \n",
    "\n",
    "print(\"Close to setup upstairs, different <mu|sigma>_<x|y|z> for all cameras\")\n",
    "scenario += 1\n",
    "\n",
    "mu_w, sigma_w = emulate_SNN_with_pose_transformation(nb_pts, cam_poses, ground_truth, e_per, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ba108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "%matplotlib notebook\n",
    "visualize_3d(100, mu_w[:,3], sigma_w[:,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1fc02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CURVE FIT TO GAUSSIAN: https://stackoverflow.com/questions/19206332/gaussian-fit-for-python/19207683"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
